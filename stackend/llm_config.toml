#
# LLM PROVIDER CONFIGURATION
#
# This document contains the configuration of the LLM providers that will be available when using StackAI
# 
# How to use this file:
# You may add as many local LLM models as you need, the only requirement for the models to work is that they must
# be compatible with the OpenAI API.
#
# To add a new local LLM model:
# 1. Uncomment the [llms.providers.local] section
# 2. Copy one of the sample local model configurations and paste it. Uncomment it after that.
# 3. Set the api_url to the base URL of the OpenAI compatible API.
# 4. Set the api_key
# 5. Set the model_name to the name of the LLM model. IMPORTANT: The model names must be unique.
# 6. Read the instructions below if you are not using external LLM providers.
# 
# How to adjust the llms that are used by default:
# 1. Locate the [default_llm] section
# 2. Change the provider to the provider you want to use by default, if you want to use a local model, change it to `provider = "Local"` (yes, uppercase)
# 3. Change the model_name to the name of the model you want to use by default
#
# How to adjust the llms that are used for each use case:
# For each of the use cases, you may change the llm provider and model as you need.
# If you only have local llms available, change the provider to `provider = "local"` and adjust
# the model_name to the name of the model you want to use.


#[llms.providers.Local]
#[llms.providers.Local.llama_3_1_70b]
#api_url = "https://api.together.xyz/v1"
#api_key = "example_api_key"
#model_name = "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"

[default_llm]
provider = "OpenAI"
model_name = "gpt-4o-mini"


[use_cases.routing_node]
provider = "TogetherAI"
model_name="meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"

[use_cases.rag_node]
provider = "TogetherAI"
model_name="meta-llama/Llama-3-8b-chat-hf"

[use_cases.csv_search]
provider = "Azure"
model_name = "gpt-40"

[use_cases.airtable_search]
provider = "Azure"
model_name = "gpt-4o-mini"

[use_cases.airtable_writer]
provider = "Azure"
model_name = "gpt-4o-mini"

[use_cases.guardrails]
provider = "Azure"
model_name = "gpt-4o-mini"

[use_cases.retrieval_util]
provider = "Azure"
model_name = "gpt-40"

[use_cases.break_to_subquestions]
provider = "Azure"
model_name = "gpt-4o-mini"

[use_cases.text_2_sql_node]
provider = "Azure"
model_name = "gpt-4o"

[use_cases.hyde_transformer]
provider = "Azure"
model_name = "gpt-4o-mini"

[use_cases.keyword_transformer]
provider = "Azure"
model_name = "gpt-4o-mini"

[use_cases.llm_document_processor]
provider = "OpenAI"
model_name = "gpt-4o-mini"

[use_cases.url_tool]
provider = "OpenAI"
model_name = "gpt-4o-mini"

[use_cases.beautiful_soup_tool]
provider = "OpenAI"
model_name = "gpt-4o-mini"

[use_cases.dataframe_tool]
provider = "OpenAI"
model_name = "gpt-4o"

[use_cases.llm_tool]
provider = "OpenAI"
model_name = "gpt-4o"

[use_cases.serp_api_tool]
provider = "OpenAI"
model_name = "gpt-4o-mini"
