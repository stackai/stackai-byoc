[llms.providers.Local]
plan_required = "enterprise"
hosted_by = "Stack AI"
display_order = 13

# REFERENCE LOCAL MODEL CONFIGURATION:
#
# You may add as many local LLM models as you need.
# To do so, please use the configuration below as a reference.
#
# [llms.providers.Local."meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"]
# endpoint_base_url = "https://api.together.xyz/v1"
# api_key = "example api key"
# model_name = "Meta Llama 3.1 Turbo"
# description = "This is a dummy configuration model that you can use as reference to create your own configuration."
# context_window = 1024
# rating_reasoning = 1
# rating_speed = 1
# rating_context = 1
# date = ""
# has_json_format = false
# has_json_schema = false
# has_vision = false
# supported_media_types = []

[llms.providers.Local.local]
model_name = "Local Model"
description = "A local model for testing and development."
context_window = 1024
rating_reasoning = 1
rating_speed = 1
rating_context = 1
date = ""
has_json_format = false
has_json_schema = false
has_vision = false
supported_media_types = []

[llms.providers.Local.default]
model_id = "local"
