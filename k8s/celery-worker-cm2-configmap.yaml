apiVersion: v1
data:
  embeddings_config.toml: "#\n# EMBEDDING PROVIDER CONFIGURATION\n# \n# This document contains the configuration of the embedding providers that will be available when using StackAI\n# \n# How to use this file:\n# You may add as many local embedding models as you need, the only requirement for the models to work is that they must\n# be compatible with the OpenAI embeddings API.\n#\n# To add a new local embedding model:\n# 1. Uncomment the [embeddings.providers.local] section\n# 2. Copy one of the sample local model configurations and paste it. Uncomment it after that.\n# 3. Set the key to the model in the [embeddings.providers.local.REPLACE_WITH_THE_MODEL_NAME]\n# 4. Set the api_url to the base URL of the OpenAI compatible API.\n# 5. Set the api_key\n# 6. Set the model_name to the name of the embedding model. IMPORTANT: The model names must be unique.\n# 7. Set the context_window to the maximum number of tokens that the embedding model can handle\n# 8. Change the [embeddings.default_model] section to use your model (Opntional if you have specified an OpenAI key)\n#    a) Locate the [embeddings.default_model] section in this file\n#    b) Change the provider to the provider you want to use by default, if you want to use a local model, change it to `provider = \"local\"`\n#    c) Change the model_name to the name of the model you want to use by default\n#\n\n# EXAMPLE LOCAL EMBEDDING MODEL CONFIGURATION:\n\n#[embeddings.providers.local]\n#[embeddings.providers.local.m2_bert_80m]\n#api_url = \"https://api.together.xyz/v1\"\n#api_key = \"example_api_key\"\n#model_name = \"togethercomputer/m2-bert-80M-8k-retrieval\"\n#context_window = 8192\n\n#[embeddings.providers.local.another_model]\n#api_url = \"https://api.together.xyz/v1\"\n#api_key = \"another_api_key\"\n#model_name = \"another_model_name\"\n#context_window = 4096\n\n[embeddings.default_model]\nmodel_name = \"text-embedding-ada-002\"\nprovider = \"openai\"\n\n[embeddings.providers.openai]\n[embeddings.providers.openai.text-embedding-3-large]\nmodel_name=\"text-embedding-3-large\"\ncontext_window=8192\n\n[embeddings.providers.openai.text-embedding-3-small]\nmodel_name=\"text-embedding-3-small\"\ncontext_window=8192\n\n[embeddings.providers.openai.text-embedding-ada-002]\nmodel_name=\"text-embedding-ada-002\"\ncontext_window=8192\n\n\n[embeddings.providers.azure]\n[embeddings.providers.azure.azure-text-embedding-ada-002]\nmodel_name=\"azure-text-embedding-ada-002\"\ncontext_window=8192\n\n[embeddings.providers.bedrock]\n[embeddings.providers.bedrock.titan-embed-text-v1]\nmodel_name=\"amazon.titan-embed-text-v1\"\ncontext_window=8000\n\n[embeddings.providers.bedrock.embed-english-v3]\nmodel_name=\"cohere.embed-english-v3\"\ncontext_window=512\n\n[embeddings.providers.bedrock.embed-multilingual-v3]\nmodel_name=\"cohere.embed-multilingual-v3\"\ncontext_window=512\n\n\n\n"
kind: ConfigMap
metadata:
  annotations:
    use-subpath: "true"
  labels:
    io.kompose.service: celery-worker
  name: celery-worker-cm2
